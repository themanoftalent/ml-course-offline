<script></script>

<h1 class="body-header">That's Not All</h1>
<p class="body-text">
  When it comes to evaluating classifiers (or any type of model), the above
  metrics are by no means exhaustive. Many other techniques exist, including
  calibration, popular diagnostic tools (specificity, likelihood ratios, etc.),
  and expectation frameworks. We cover the closely-related concepts of ROC and
  AUC in an upcoming article, so look out for that!
  <br /><br />
  Additionally, while the concepts we introduced in this article were done so in
  the context of binary classification, they can all be applied to multiclass settings
  as well. So give them a try!
</p>
<br />
<hr />
<br />
<p class="body-text">
  Thanks for reading. We hope that the article is insightful no matter where you
  are along your Machine Learning journey, and that you came away with a better
  understanding of some of the difficulties of evaluating classification models.
  <br /><br />
  To learn more about Machine Learning, check out our
  <a class="on-end" href="https://aws.amazon.com/machine-learning/mlu/"
    >self-paced courses</a
  >, our
  <a
    class="on-end"
    href="https://www.youtube.com/channel/UC12LqyqTQYbXatYS9AA7Nuw"
    >YouTube videos</a
  >, and the
  <a class="on-end" href="https://d2l.ai/">Dive into Deep Learning</a>
  textbook. If you have any comments or ideas related to
  <a class="on-end" href="https://mlu-explain.github.io/"
    >MLU-Explain articles</a
  >, feel free to reach out
  <a class="on-end" href="https://twitter.com/jdwlbr">directly</a>. The code for
  this article is available
  <a class="on-end" href="https://github.com/aws-samples/aws-mlu-explain"
    >here</a
  >.
  <br /><br />
  A special thanks to <span class="bold">Brent Werness</span> and
  <span class="bold">Lucía Santamaría</span> for feedback and edits.
</p>

<style>
  hr {
    width: 10%;
    margin: 2.5rem auto;
  }

  @media screen and (max-width: 950px) {
  }
</style>
